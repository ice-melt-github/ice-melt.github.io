<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Python自然语言处理07 从文本提取信息 | 夕兮曦兮的个人网站</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="ice-melt's Blog">
  
  <meta name="description" content="本章回答下列问题: (1)如何能构建一个系统,以至从非结构化文本中提取结构化数据? (2)有哪些稳健的方法识别一个文本描述的实体和关系? (3)哪些语料库适合这项工作,如何使用它们来训练和评估模型? 使用最后两章技术解决分块和命名实体识别的问题">
<meta name="keywords" content="Python自然语言处理,NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="Python自然语言处理07 从文本提取信息">
<meta property="og:url" content="https://ice-melt.github.io/2019/05/08/Python-NLP-07/index.html">
<meta property="og:site_name" content="夕兮曦兮的个人网站">
<meta property="og:description" content="本章回答下列问题: (1)如何能构建一个系统,以至从非结构化文本中提取结构化数据? (2)有哪些稳健的方法识别一个文本描述的实体和关系? (3)哪些语料库适合这项工作,如何使用它们来训练和评估模型? 使用最后两章技术解决分块和命名实体识别的问题">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-05-08T03:57:57.590Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python自然语言处理07 从文本提取信息">
<meta name="twitter:description" content="本章回答下列问题: (1)如何能构建一个系统,以至从非结构化文本中提取结构化数据? (2)有哪些稳健的方法识别一个文本描述的实体和关系? (3)哪些语料库适合这项工作,如何使用它们来训练和评估模型? 使用最后两章技术解决分块和命名实体识别的问题">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script>
  

  
  

  
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>
</html>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
      <header id="header">
    <div id="banner"></div>
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">ice-melt&#39;s Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a href="/">
                        <i class="fa fa-home"></i>
                        <span>Home</span>
                    </a>
                    
                    <a href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>Archives</span>
                    </a>
                    
                    <a href="/about">
                        <i class="fa fa-user"></i>
                        <span>About</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
        <div id="header-row">
            <div id="logo">
                <a href="/">
                    <img src="/images/logo.png" alt="logo">
                </a>
            </div>
            <div class="header-info">
                <div id="header-title">
                    
                    <h2>
                        ice-melt&#39;s Blog
                    </h2>
                    
                </div>
                <div id="header-description">
                    
                    <h3>
                        冰冻三尺 非一日之寒 积土成山 非斯须之作。
                    </h3>
                    
                </div>
            </div>
            <nav class="header-nav">
                <div class="social">
                    
                        <a title="ice-melt" target="_blank" href="https://ice-melt.github.io/">
                            <i class="fa fa-home fa-2x"></i></a>
                    
                        <a title="Github" target="_blank" href="//github.com/ice-melt">
                            <i class="fa fa-github fa-2x"></i></a>
                    
                        <a title="Weibo" target="_blank" href="//weibo.com/ice-melt">
                            <i class="fa fa-weibo fa-2x"></i></a>
                    
                </div>
            </nav>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-Python-NLP-07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="post-title" itemprop="name">
      Python自然语言处理07 从文本提取信息
    </h1>
    <div class="post-title-bar">
      <ul>
          
        <li>
          <i class="fa fa-calendar"></i>  2019-05-08
        </li>
        <li>
          <i class="fa fa-eye"></i>
          <span id="busuanzi_value_page_pv"></span>
        </li>
      </ul>
    </div>
  

          
      </header>
    
    <div class="article-entry post-content" itemprop="articleBody">
      
            
            <p>本章回答下列问题:</p>
<p>(1)如何能构建一个系统,以至从非结构化文本中提取结构化数据?</p>
<p>(2)有哪些稳健的方法识别一个文本描述的实体和关系?</p>
<p>(3)哪些语料库适合这项工作,如何使用它们来训练和评估模型?</p>
<p>使用最后两章技术解决分块和命名实体识别的问题<br><a id="more"></a></p>
<p>一　信息提取<br>信息有很多种’形状’和’大小’,一个重要的形式是结构化数据:实体和关系的规范和可预测的组织。例如:我们可能对公司和地点之间的关系,可用关系数据库存储。</p>
<p>但如果我们尝试从文本中获得相似的信息,事情就比较麻烦了。如何从一段文字中发现一个实体和关系的表呢?</p>
<p>然后,利用强大的查询工具,如SQL,这种从文本获取意义的方法被称为’信息提取’</p>
<p>信息提取有许多应用,包括商业智能、简历收获、媒体分析、情感检测、专利检索及电子邮件扫描。当前研究的一个特别重要的领域是提取出电子科学文献的结构化数据,特别是在生物学和医学领域。</p>
<h1 id="信息提取结构"><a href="#信息提取结构" class="headerlink" title="信息提取结构"></a>信息提取结构</h1><p>要执行前面３个任务,句子分割器、分词器和词性标注器</p>
<p>import nltk, re, pprint<br>def ie_preprocess(document):<br>    sentences = nltk.sent_tokenize(document)                      #句子分割<br>    sentences = [nltk.word_tokenize(sent) for sent in sentences]  #分词<br>    sentences = [nltk.pos_tag(sent) for sent in sentence]         #词性标注器<br>二　分块<br>用于实体识别的基本技术是分块(chunking)</p>
<p>小框显示词级标识符和词性标注,同时,大框显示较高级的程序分块</p>
<p>在本节上,我们将在较深的层面上探讨程序分块,以组块的定义和表示开始,我们将看到正则表达式和n-gram方法分块,使用CoNLL-2000分块语料库开发和评估分块器。</p>
<h1 id="名词短语分块"><a href="#名词短语分块" class="headerlink" title="名词短语分块"></a>名词短语分块</h1><p>NP-chunking（名词短语分块),寻找单独名词短语对应的块</p>
<p>NP－分块信息最有用的来源之一是词性标记。这是在信息提取系统中进行词性标注的动机之一。</p>
<p>为了创建NP－分块,首先定义分块语法,规定句子应如何分块。在本例中,使用一个正则表达式规则定义一个简单的语法。</p>
<p>这条规则是NP-分块有可选的且后面跟着任意数目形容词的限定词和名词组成。使用此语法,我们创建了组块分析器,测试我门的例句。结果得到树状图,可以输出或显示图形。</p>
<p>sentence = [(“the”,”DT”),(“little”,”JJ”),(“yellow”,”JJ”),(“dog”,”NN”),(“barked”,”VBD”),(“at”,”IN”),(“the”,”DT”),(“cat”,”NN”)]<br>grammar = “NP: {<dt>?<jj>*<nn>}”<br>cp = nltk.RegexpParser(grammar)<br>result = cp.parse(sentence)<br>print result<br>(S<br>  (NP the/DT little/JJ yellow/JJ dog/NN)<br>  barked/VBD<br>  at/IN<br>  (NP the/DT cat/NN))<br>result.draw()</nn></jj></dt></p>
<h1 id="标记模式"><a href="#标记模式" class="headerlink" title="标记模式"></a>标记模式</h1><p>使用图形界面nltk.app.chunkparser()</p>
<h1 id="用正则表达式分块"><a href="#用正则表达式分块" class="headerlink" title="用正则表达式分块"></a>用正则表达式分块</h1><p>grammer = r”””<br>   NP: {<dt|pp\$>?<jj>*<nn>}    #匹配一个可选的限定词或所有格代名词<br>       {<nnp>+}                 #匹配一个或多个专有名词<br>“””<br>cp = nltk.RegexpParser(grammer)<br>sentence = [(“Rapunzel”,”NNP”),(“let”,”VBD”),(“down”, “RP”),(“her”,”PP$”),(“long”,”JJ”),(“golden”,”JJ”),(“hair”,”NN”)]<br>print cp.parse(sentence)<br>(S<br>  (NP Rapunzel/NNP)<br>  let/VBD<br>  down/RP<br>  (NP her/PP$ long/JJ golden/JJ hair/NN))<br>nouns = [(“money”,”NN”),(“market”,”NN”),(“fund”,”NN”)]<br>grammar = “NP: {<nn><nn>}”  #如果将匹配两个连续名词的文本的规则应用到包含３个连续名词的文本中,则只有前两个名词被分块<br>cp = nltk.RegexpParser(grammar)<br>print cp.parse(nouns)<br>(S (NP money/NN market/NN) fund/NN)</nn></nn></nnp></nn></jj></dt|pp\$></p>
<h1 id="探索文本语料库"><a href="#探索文本语料库" class="headerlink" title="探索文本语料库"></a>探索文本语料库</h1><p>使用分块器可以在已标注的语料库中提取匹配特定词性标记序列的短语</p>
<p>cp = nltk.RegexpParser(‘CHUNK: {<v.*> <to> <v.*>}’)<br>brown = nltk.corpus.brown<br>for sent in brown.tagged_sents():<br>    tree = cp.parse(sent)<br>    for subtree in tree.subtrees():<br>        if subtree.label() == ‘CHUNK’:<br>            print subtree<br>(CHUNK combined/VBN to/TO achieve/VB)<br>(CHUNK continue/VB to/TO place/VB)<br>(CHUNK serve/VB to/TO protect/VB)<br>(CHUNK wanted/VBD to/TO wait/VB)<br>(CHUNK allowed/VBN to/TO place/VB)<br>……</v.*></to></v.*></p>
<h1 id="缝隙"><a href="#缝隙" class="headerlink" title="缝隙"></a>缝隙</h1><p>为不包括在大块中的标识符序列定义一个缝隙</p>
<p>加缝隙是从大块中去除标识符序列的过程</p>
<p>grammar = r”””<br>NP:<br>   {&lt;.*&gt;+}<br>   }<vbd|in>+{“””<br>sentence = [(“the”,”DT”),(“little”,”JJ”),(“yellow”,”JJ”),(“dog”,”NN”),(“barked”,”VBD”),(“at”,”IN”),(“the”,”DT”),(“cat”,”NN”)]<br>cp = nltk.RegexpParser(grammar)<br>print cp.parse(sentence)<br>(S<br>  (NP the/DT little/JJ yellow/JJ dog/NN)<br>  barked/VBD<br>  at/IN<br>  (NP the/DT cat/NN))</vbd|in></p>
<h1 id="分块的表示-标记与树状图"><a href="#分块的表示-标记与树状图" class="headerlink" title="分块的表示:标记与树状图"></a>分块的表示:标记与树状图</h1><p>作为标注和分析之间的中间状态,块结构可以使用标记或树状图来表示。使用最广泛的表示是IOB标记</p>
<p>在这个方案中,每个标识符被用３个特殊的块标签之一标注,Ｉ（inside,内部),Ｏ（outside,外部)或Ｂ（begin,开始)。</p>
<p>Ｂ标志着它是分块的开始。块内的标识符子序列被标志为Ｉ,其他为Ｏ</p>
<p>Ｂ和Ｉ标记是块类型的后缀,如B-NP, I-NP。</p>
<p>NLTK用树状图作为分块的内部表示,却提供这些树状图与IOB之间格式转换的方法</p>
<p>３　开发和评估分块器<br>如何评估分块器</p>
<h1 id="读取IOB格式与CoNLL2000分块语料库"><a href="#读取IOB格式与CoNLL2000分块语料库" class="headerlink" title="读取IOB格式与CoNLL2000分块语料库"></a>读取IOB格式与CoNLL2000分块语料库</h1><p>CoNLL2000分块语料库包含27万词的《华尔街日报文本》,分为’训练’和’测试’两部分,标注有词性标记和IOB格式分块标记。</p>
<p>from nltk.corpus import conll2000<br>print conll2000.chunked_sents(‘train.txt’)[99]<br>(S<br>  (PP Over/IN)<br>  (NP a/DT cup/NN)<br>  (PP of/IN)<br>  (NP coffee/NN)<br>  ,/,<br>  (NP Mr./NNP Stone/NNP)<br>  (VP told/VBD)<br>  (NP his/PRP$ story/NN)<br>  ./.)<br>包含３中分块类型:NP分块,VP分块,PP分块<br>print conll2000.chunked_sents(‘train.txt’, chunk_types=[‘NP’])[99]  #只选择NP分块</p>
<h1 id="简单评估和基准"><a href="#简单评估和基准" class="headerlink" title="简单评估和基准"></a>简单评估和基准</h1><p>cp = nltk.RegexpParser(“”)     #不分块<br>test_sents = conll2000.chunked_sents(‘test.txt’,chunk_types=[‘NP’])<br>print cp.evaluate(test_sents)  #评估结果<br>ChunkParse score:<br>    IOB Accuracy:  43.4%%<br>    Precision:      0.0%%<br>    Recall:         0.0%%<br>    F-Measure:      0.0%%<br>grammar = r”NP: {&lt;[CDJNP].*&gt;+}”<br>cp = nltk.RegexpParser(grammar)     #初级的正则表达式分块器<br>test_sents = conll2000.chunked_sents(‘test.txt’)<br>print cp.evaluate(test_sents)  #评估结果<br>ChunkParse score:<br>    IOB Accuracy:  62.5%%<br>    Precision:     70.6%%<br>    Recall:        38.5%%<br>    F-Measure:     49.8%%<br>使用unigram标注器对名词短语分块</p>
<h1 id="使用训练语料找到对每个词性标记最有可能的块标记（I、O或B"><a href="#使用训练语料找到对每个词性标记最有可能的块标记（I、O或B" class="headerlink" title="使用训练语料找到对每个词性标记最有可能的块标记（Ｉ、Ｏ或Ｂ)"></a>使用训练语料找到对每个词性标记最有可能的块标记（Ｉ、Ｏ或Ｂ)</h1><h1 id="可以用unigram标注器建立一个分块器-但不是要确定每个词的正确词性标记-而是给定每个词的词性标记-尝试确定正确的块标记"><a href="#可以用unigram标注器建立一个分块器-但不是要确定每个词的正确词性标记-而是给定每个词的词性标记-尝试确定正确的块标记" class="headerlink" title="可以用unigram标注器建立一个分块器,但不是要确定每个词的正确词性标记,而是给定每个词的词性标记,尝试确定正确的块标记"></a>可以用unigram标注器建立一个分块器,但不是要确定每个词的正确词性标记,而是给定每个词的词性标记,尝试确定正确的块标记</h1><p>class UnigramChunker(nltk.ChunkParserI):<br>    def <strong>init</strong>(self, train_sents):<br>        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]<br>        self.tagger = nltk.UnigramTagger(train_data)</p>
<pre><code>def parse(self, sentence):
    pos_tags = [pos for (word,pos) in sentence]
    tagged_pos_tags = self.tagger.tag(pos_tags)
    chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]
    #为词性标注IOB块标记
    conlltags = [(word, pos, chunktag) for ((word,pos),chunktag) in zip(sentence, chunktags)]
    return nltk.chunk.conlltags2tree(conlltags) #转换成分块树状图
</code></pre><h1 id="使用CoNLL2000分块语料库训练"><a href="#使用CoNLL2000分块语料库训练" class="headerlink" title="使用CoNLL2000分块语料库训练"></a>使用CoNLL2000分块语料库训练</h1><p>test_sents = conll2000.chunked_sents(‘test.txt’, chunk_types=[‘NP’])<br>train_sents = conll2000.chunked_sents(‘train.txt’, chunk_types=[‘NP’])<br>unigram_chunker = UnigramChunker(train_sents)<br>print unigram_chunker.evaluate(test_sents)<br>ChunkParse score:<br>    IOB Accuracy:  92.9%%<br>    Precision:     79.9%%<br>    Recall:        86.8%%<br>    F-Measure:     83.2%%<br>postags = sorted(set(pos for sent in train_sents for (word,pos) in sent.leaves()))<br>print unigram_chunker.tagger.tag(postags)<br>[(u’#’, u’B-NP’), (u’$’, u’B-NP’), (u”‘’”, u’O’), (u’(‘, u’O’), (u’)’, u’O’), (u’,’, u’O’), (u’.’, u’O’), (u’:’, u’O’), (u’CC’, u’O’), (u’CD’, u’I-NP’), (u’DT’, u’B-NP’), (u’EX’, u’B-NP’), (u’FW’, u’I-NP’), (u’IN’, u’O’), (u’JJ’, u’I-NP’), (u’JJR’, u’B-NP’), (u’JJS’, u’I-NP’), (u’MD’, u’O’), (u’NN’, u’I-NP’), (u’NNP’, u’I-NP’), (u’NNPS’, u’I-NP’), (u’NNS’, u’I-NP’), (u’PDT’, u’B-NP’), (u’POS’, u’B-NP’), (u’PRP’, u’B-NP’), (u’PRP$’, u’B-NP’), (u’RB’, u’O’), (u’RBR’, u’O’), (u’RBS’, u’B-NP’), (u’RP’, u’O’), (u’SYM’, u’O’), (u’TO’, u’O’), (u’UH’, u’O’), (u’VB’, u’O’), (u’VBD’, u’O’), (u’VBG’, u’O’), (u’VBN’, u’O’), (u’VBP’, u’O’), (u’VBZ’, u’O’), (u’WDT’, u’B-NP’), (u’WP’, u’B-NP’), (u’WP$’, u’B-NP’), (u’WRB’, u’O’), (u’``’, u’O’)]</p>
<h1 id="使用训练语料找到对每个词性标记最有可能的块标记（I、O或B-1"><a href="#使用训练语料找到对每个词性标记最有可能的块标记（I、O或B-1" class="headerlink" title="使用训练语料找到对每个词性标记最有可能的块标记（Ｉ、Ｏ或Ｂ)"></a>使用训练语料找到对每个词性标记最有可能的块标记（Ｉ、Ｏ或Ｂ)</h1><h1 id="可以用bigram标注器建立一个分块器-但不是要确定每个词的正确词性标记-而是给定每个词的词性标记-尝试确定正确的块标记"><a href="#可以用bigram标注器建立一个分块器-但不是要确定每个词的正确词性标记-而是给定每个词的词性标记-尝试确定正确的块标记" class="headerlink" title="可以用bigram标注器建立一个分块器,但不是要确定每个词的正确词性标记,而是给定每个词的词性标记,尝试确定正确的块标记"></a>可以用bigram标注器建立一个分块器,但不是要确定每个词的正确词性标记,而是给定每个词的词性标记,尝试确定正确的块标记</h1><p>class BigramChunker(nltk.ChunkParserI):<br>    def <strong>init</strong>(self, train_sents):<br>        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]<br>        self.tagger = nltk.BigramTagger(train_data)</p>
<pre><code>def parse(self, sentence):
    pos_tags = [pos for (word,pos) in sentence]
    tagged_pos_tags = self.tagger.tag(pos_tags)
    chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]
    #为词性标注IOB块标记
    conlltags = [(word, pos, chunktag) for ((word,pos),chunktag) in zip(sentence, chunktags)]
    return nltk.chunk.conlltags2tree(conlltags) #转换成分块树状图
</code></pre><p>bigram_chunker = BigramChunker(train_sents)<br>print bigram_chunker.evaluate(test_sents)<br>ChunkParse score:<br>    IOB Accuracy:  93.3%%<br>    Precision:     82.3%%<br>    Recall:        86.8%%<br>    F-Measure:     84.5%%</p>
<h1 id="训练基于分类器的分块器"><a href="#训练基于分类器的分块器" class="headerlink" title="训练基于分类器的分块器"></a>训练基于分类器的分块器</h1><p>有时词性标记不足以确定一个句子应如何分块</p>
<p>安装ocaml   </p>
<p>安装maxnet     最大熵</p>
<p>class ConsecutiveNPChunkTagger(nltk.TaggerI):<br>    def <strong>init</strong>(self, train_sents):<br>        train_set = []<br>        for tagged_sent in train_sents:<br>            untagged_sent = nltk.tag.untag(tagged_sent)<br>            history = []<br>            for i, (word,tag) in enumerate(tagged_sent):<br>                featureset = npchunk_features(untagged_sent, i, history)<br>                train_set.append( (featureset, tag) )<br>                history.append(tag)<br>        self.classifier = nltk.MaxentClassifier.train(train_set, algorithm=’megam’, trace=0)　#最大熵<br>    def tag(self, sentence):<br>        history = []<br>        for i, word in enumerate(sentence):<br>            featureset = npchunk_features(sentence, i, history)<br>            tag = self.classifier.classify(featureset)<br>            history.append(tag)<br>        return zip(sentence, history)</p>
<p>class ConsecutiveNPChunker(nltk.ChunkParserI):<br>    def <strong>init</strong>(self, train_sents):<br>        tagged_sents = [[((w,t),c) for (w,t,c) in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]<br>        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)<br>    def parse(self, sentence):<br>        tagged_sents = self.tagger.tag(sentence)<br>        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]<br>        return nltk.chunk.conlltags2tree(conlltags)<br>def npchunk_features(sentence, i, history):<br>    word, pos = sentence[i]<br>    return {“pos”: pos} #只提供当前标识符的词性标记<br>chunker = ConsecutiveNPChunker(train_sents)<br>print chunker.evaluate(test_sents)<br>ChunkParse score:<br>    IOB Accuracy:  92.9%%<br>    Precision:     79.9%%<br>    Recall:        86.7%%<br>    F-Measure:     83.2%%<br>def npchunk_features(sentence, i, history):<br>    word, pos = sentence[i]<br>    if i == 0:<br>        prevword, prevpos = “<start>“, “<start>“<br>    else:<br>        prevword, prevpos = sentence[i-1]<br>   return {“pos”: pos, “prevpos”: prevpos} #模拟相邻标记之间的相互作用<br>chunker = ConsecutiveNPChunker(train_sents)<br>print chunker.evaluate(test_sents)<br>ChunkParse score:<br>    IOB Accuracy:  93.7%%<br>    Precision:     82.1%%<br>    Recall:        87.2%%<br>    F-Measure:     84.5%%<br>def npchunk_features(sentence, i, history):<br>    word, pos = sentence[i]<br>    if i == 0:<br>        prevword, prevpos = “<start>“, “<start>“<br>    else:<br>        prevword, prevpos = sentence[i-1]<br>    return {“pos”: pos, “word”: word, “prevpos”: prevpos}   #增加词的内容<br>chunker = ConsecutiveNPChunker(train_sents)<br>print chunker.evaluate(test_sents)<br>ChunkParse score:<br>    IOB Accuracy:  94.2%%<br>    Precision:     83.2%%<br>    Recall:        88.3%%<br>    F-Measure:     85.7%%<br>def npchunk_features(sentence, i, history):<br>    word, pos = sentence[i]<br>    if i == 0:<br>        prevword, prevpos = “<start>“, “<start>“<br>    else:<br>        prevword, prevpos = sentence[i-1]<br>    if i == len(sentence)-1:<br>        nextword, nextpos = “<end>“, “<end>“<br>    else:<br>        nextword, nextpos = sentence[i+1]<br>    return {“pos”: pos,<br>            “word”: word,<br>            “prevpos”: prevpos,<br>            “nextpos”: nextpos,<br>            “prevpos+pos”: “%s+%s” % (prevpos, pos),<br>            “pos+nextpos”: “%s+%s” % (pos, nextpos),<br>            “tags-since-dt”: tags_since_dt(sentence, i)}  #预取特征、配对功能和复杂的语境特征<br>def tags_since_dt(sentence, i):<br>    tags = set()<br>    for word, pos in sentence[:i]:<br>        if pos == “DT”:<br>            tags = set()<br>        else:<br>            tags.add(pos)<br>    return ‘+’.join(sorted(tags))<br>chunker = ConsecutiveNPChunker(train_sents)<br>print chunker.evaluate(test_sents)<br>ChunkParse score:<br>    IOB Accuracy:  96.0%%<br>    Precision:     88.8%%<br>    Recall:        91.1%%<br>    F-Measure:     89.9%%<br>四　语言结构中的递归</end></end></start></start></start></start></start></start></p>
<h1 id="用级联分块器构建嵌套结构"><a href="#用级联分块器构建嵌套结构" class="headerlink" title="用级联分块器构建嵌套结构"></a>用级联分块器构建嵌套结构</h1><p>只需创建一个包含递归规则的多级的分块语法,就可以建立任意深度的分块结构</p>
<p>例子展示名词短语、介词短语、动词短语和句子的模式</p>
<p>grammar = r”””<br>   NP: {<dt|jj|nn.*>+}<br>   PP: {<in><np>}<br>   VP: {<vb.*><np|pp|clause>+$}<br>   CLAUSE: {<np><vp>}<br>“””<br>cp = nltk.RegexpParser(grammar)<br>sentence = [(“Mary”,”NN”), (“saw”,”VBD”),(“the”,”DT”),(“cat”,”NN”),(“sit”,”VB”),(“on”,”IN”),(“the”,”DT”),(“mat”,”NN”)]<br>print cp.parse(sentence)<br>(S<br>  (NP Mary/NN)<br>  saw/VBD   #无法识别VP<br>  (CLAUSE<br>    (NP the/DT cat/NN)<br>    (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))<br>cp = nltk.RegexpParser(grammar, loop=2)  #添加循环<br>print cp.parse(sentence)<br>(S<br>  (CLAUSE<br>    (NP Mary/NN)<br>    (VP<br>      saw/VBD<br>      (CLAUSE<br>        (NP the/DT cat/NN)<br>        (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))))</vp></np></np|pp|clause></vb.*></np></in></dt|jj|nn.*></p>
<h1 id="树状图"><a href="#树状图" class="headerlink" title="树状图"></a>树状图</h1><p>在NLTK中,创建树状图,方法是给节点添加标签和一个子链表</p>
<h1 id="树遍历"><a href="#树遍历" class="headerlink" title="树遍历"></a>树遍历</h1><p>使用递归函数来遍历树是标准的做法</p>
<p>五　命名实体识别</p>
<p>命名实体识别（NER)系统的目标是识别所有文字提及的命名实体。这可以分解成两个子任务:确定NE的边界和确定其类型。命名实体识别经常是信息提取中关系识别的前奏,也有助于其他任务。例如:在问答系统（QA)中,我们试图提高信息检索的精确度,不用返回整个页面而只是包含用户问题的答案的那部分。大多数QA系统利用标准信息检索返回的文件,然后尝试分离文档中包含答案的最小的文本分段。P303,例如问题:Who was the first President of the US?被检索的文档中包含答案,但我们想得到的答案应该是X was the first President of the US的形式,其中X不仅是一个名词短语也是一个PER类型的命名实体。<br>如何识别命名实体呢?一种方法是查找适当的名称列表,但问题是许多实体措辞有歧义,如May和North可能是日期和地点</p>
<p>因此我们需要能够识别多标识符序列的开头和结尾</p>
<p>NER是一个非常适合用于分类器类型的方法。</p>
<p>NLTK提供了一个已经训练好的可以识别命名实体的分类器,使用函数nltk.ne_chunk()访问。</p>
<p>sent = nltk.corpus.treebank.tagged_sents()[22]<br>print nltk.ne_chunk(sent, binary=True)    #如果设置参数binary=True,那么命名实体只被标注为NE<br>(S<br>  The/DT<br>  (NE U.S./NNP)<br>  is/VBZ<br>  one/CD<br>  of/IN<br>print nltk.ne_chunk(sent)    #PERSON, ORGANIZATION and GPE<br>(S<br>  The/DT<br>  (GPE U.S./NNP)<br>  is/VBZ<br>  ……<br>  (PERSON Brooke/NNP T./NNP Mossman/NNP)<br>  ,/,<br>  a/DT<br>  professor/NN<br>  of/IN<br>  pathlogy/NN<br>  at/IN<br>  the/DT<br>  (ORGANIZATION University/NNP)<br>  of/IN<br>  (PERSON Vermont/NNP College/NNP)<br>  of/IN<br>  (GPE Medicine/NNP)<br>六　关系抽取<br>只要文本中的命名实体被识别,我们就可以提取它们之间存在的关系。</p>
<p>方法之一是首先寻找所有(X, a, Y)形式的三元组,其中X和Y是指定类型的命名实体,a表示X和Y之间关系的字符串</p>
<p>IN = re.compile(r’.*\bin\b(?!\b.+ing)’)<br>for doc in nltk.corpus.ieer.parsed_docs(‘NYT_19980315’):<br>    for rel in nltk.sem.extract_rels(‘ORG’, ‘LOC’, doc, corpus=’ieer’, pattern=IN):<br>        print nltk.sem.relextract.rtuple(rel)<br>[ORG: u’WHYY’] u’in’ [LOC: u’Philadelphia’]<br>[ORG: u’McGlashan &amp; Sarrail’] u’firm in’ [LOC: u’San Mateo’]<br>[ORG: u’Freedom Forum’] u’in’ [LOC: u’Arlington’]<br>[ORG: u’Brookings Institution’] u’, the research group in’ [LOC: u’Washington’]<br>[ORG: u’Idealab’] u’, a self-described business incubator based in’ [LOC: u’Los Angeles’]<br>[ORG: u’Open Text’] u’, based in’ [LOC: u’Waterloo’]<br>七　深入阅读</p>

            <div class="post-copyright">
    <div class="content">
        <p>最后更新： 2019年05月08日 11:57</p>
        <p>原始链接： <a class="post-url" href="/2019/05/08/Python-NLP-07/" title="Python自然语言处理07 从文本提取信息">https://ice-melt.github.io/2019/05/08/Python-NLP-07/</a></p>
        <footer>
            <a href="https://ice-melt.github.io">
                <img src="/images/logo.png" alt="ice-melt">
                ice-melt
            </a>
        </footer>
    </div>
</div>

      
        
            
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;">赏</a>
</div>

<div id="reward" class="post-modal reward-lay">
    <a class="close" href="javascript:;" id="reward-close">×</a>
    <span class="reward-title">
        <i class="icon icon-quote-left"></i>
        您的支持是我原创的动力
        <i class="icon icon-quote-right"></i>
    </span>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/images/wechat_code.jpg" alt="打赏二维码">
        </div>
        <div class="reward-select">
            
            <label class="reward-select-item checked" data-id="wechat" data-wechat="/images/wechat_code.jpg">
                <img class="reward-select-item-wechat" src="/images/wechat.png" alt="微信">
            </label>
            
            
            <label class="reward-select-item" data-id="alipay" data-alipay="/images/alipay_code.jpg">
                <img class="reward-select-item-alipay" src="/images/alipay.png" alt="支付宝">
            </label>
            
        </div>
    </div>
</div>


        
    </div>
    <footer class="article-footer">
        
        
<div class="post-share">
    <a href="javascript:;" id="share-sub" class="post-share-fab">
        <i class="fa fa-share-alt"></i>
    </a>
    <div class="post-share-list" id="share-list">
        <ul class="share-icons">
          <li>
            <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://ice-melt.github.io/2019/05/08/Python-NLP-07/&title=《Python自然语言处理07 从文本提取信息》 — 夕兮曦兮的个人网站&pic=https://ice-melt.github.ioimages/logo.png" data-title="微博">
              <i class="fa fa-weibo"></i>
            </a>
          </li>
          <li>
            <a class="weixin share-sns" id="wxFab" href="javascript:;" data-title="微信">
              <i class="fa fa-weixin"></i>
            </a>
          </li>
          <li>
            <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://ice-melt.github.io/2019/05/08/Python-NLP-07/&title=《Python自然语言处理07 从文本提取信息》 — 夕兮曦兮的个人网站&source=本章回答下列问题:
(1)如何能构建一个系统,以至从非结构化文本中提取结构化数据?
(2)有哪些稳健的方法识别一个文本描述的实体和关系?
(3)哪些语料库..." data-title="QQ">
              <i class="fa fa-qq"></i>
            </a>
          </li>
          <li>
            <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://ice-melt.github.io/2019/05/08/Python-NLP-07/" data-title="Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          </li>
          <li>
            <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Python自然语言处理07 从文本提取信息》 — 夕兮曦兮的个人网站&url=https://ice-melt.github.io/2019/05/08/Python-NLP-07/&via=https://ice-melt.github.io" data-title="Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
          <li>
            <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://ice-melt.github.io/2019/05/08/Python-NLP-07/" data-title="Google+">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        </ul>
     </div>
</div>
<div class="post-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;" id="wxShare-close">×</a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=https://ice-melt.github.io/2019/05/08/Python-NLP-07/" alt="微信分享二维码">
</div>

<div class="mask"></div>

        
        <ul class="article-footer-menu">
            
            
  <li class="article-footer-tags">
    <i class="fa fa-tags"></i>
      
    <a href="/tags/Python自然语言处理/" class="color3">Python自然语言处理</a>
      
    <a href="/tags/NLP/" class="color4">NLP</a>
      
  </li>

        </ul>
        
    </footer>
  </div>
</article>


    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#信息提取结构"><span class="post-toc-text">信息提取结构</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#名词短语分块"><span class="post-toc-text">名词短语分块</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#标记模式"><span class="post-toc-text">标记模式</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#用正则表达式分块"><span class="post-toc-text">用正则表达式分块</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#探索文本语料库"><span class="post-toc-text">探索文本语料库</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#缝隙"><span class="post-toc-text">缝隙</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#分块的表示-标记与树状图"><span class="post-toc-text">分块的表示:标记与树状图</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#读取IOB格式与CoNLL2000分块语料库"><span class="post-toc-text">读取IOB格式与CoNLL2000分块语料库</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#简单评估和基准"><span class="post-toc-text">简单评估和基准</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#使用训练语料找到对每个词性标记最有可能的块标记（I、O或B"><span class="post-toc-text">使用训练语料找到对每个词性标记最有可能的块标记（Ｉ、Ｏ或Ｂ)</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#可以用unigram标注器建立一个分块器-但不是要确定每个词的正确词性标记-而是给定每个词的词性标记-尝试确定正确的块标记"><span class="post-toc-text">可以用unigram标注器建立一个分块器,但不是要确定每个词的正确词性标记,而是给定每个词的词性标记,尝试确定正确的块标记</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#使用CoNLL2000分块语料库训练"><span class="post-toc-text">使用CoNLL2000分块语料库训练</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#使用训练语料找到对每个词性标记最有可能的块标记（I、O或B-1"><span class="post-toc-text">使用训练语料找到对每个词性标记最有可能的块标记（Ｉ、Ｏ或Ｂ)</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#可以用bigram标注器建立一个分块器-但不是要确定每个词的正确词性标记-而是给定每个词的词性标记-尝试确定正确的块标记"><span class="post-toc-text">可以用bigram标注器建立一个分块器,但不是要确定每个词的正确词性标记,而是给定每个词的词性标记,尝试确定正确的块标记</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#训练基于分类器的分块器"><span class="post-toc-text">训练基于分类器的分块器</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#用级联分块器构建嵌套结构"><span class="post-toc-text">用级联分块器构建嵌套结构</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#树状图"><span class="post-toc-text">树状图</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#树遍历"><span class="post-toc-text">树遍历</span></a></li></ol>
        </nav>
    </aside>
    

<nav id="article-nav">
  
  
    <a href="/2019/05/06/Python-NLP-01/" id="article-nav-older" class="article-nav-link-wrap">
      <span class="article-nav-title">Python自然语言处理01 语言处理与Python</span>
      <i class="fa fa-hand-o-right" aria-hidden="true"></i>
    </a>
  
</nav>



    
        <div id="SOHUCS" sid="Python-NLP-07"></div>
<script type="text/javascript">
    (function(){
        var appid = 'cytRPCpOX';
        var conf = 'prod_1e65dc7b851067d2e5fa952e667c6b16';
        var width = window.innerWidth || document.documentElement.clientWidth;
        if (width < 960) {
            window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>'); } else { var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})}); } })(); </script>
    
</section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      
<p>
    <span id="busuanzi_container_site_uv" style="display:none">
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style="display:none">
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2019 ice-melt<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
  var mihoConfig = {
      root: "https://ice-melt.github.io",
      animate: true,
      isHome: false,
      share: true,
      reward: 1
  }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-tag" title="Tags">
        <i class="fa fa-tags"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            
        </div>
        <div id="sidebar-menu-box-tags">
            <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/Python自然语言处理/" style="font-size: 20px;">Python自然语言处理</a> <a href="/tags/人工智能/" style="font-size: 10px;">人工智能</a> <a href="/tags/建站/" style="font-size: 10px;">建站</a>
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>
<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a href="/">
                    <i class="fa fa-home"></i><span>Home</span>
                </a>
            </li>
            
            <li>
                <a href="/archives">
                    <i class="fa fa-archive"></i><span>Archives</span>
                </a>
            </li>
            
            <li>
                <a href="/about">
                    <i class="fa fa-user"></i><span>About</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/Python自然语言处理/" style="font-size: 20px;">Python自然语言处理</a> <a href="/tags/人工智能/" style="font-size: 10px;">人工智能</a> <a href="/tags/建站/" style="font-size: 10px;">建站</a>
        </div>
    </div>
</div>
<div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>
<script src="/js/search.js"></script>
<script src="/js/main.js"></script>


  <script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script>
  <div id="particles"></div>
  <script src="/js/particles.js"></script>







  <link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">
  <script src="//cdn.bootcss.com/scrollReveal.js/3.0.5/scrollreveal.js"></script>
  <script src="/js/animate.js"></script>


  <script src="/js/pop-img.js"></script>
  <script>
     $(".article-entry p img").popImg();
  </script>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>